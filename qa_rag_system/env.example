# LLM Configuration
# Option 1: OpenAI
OPENAI_API_KEY=your_openai_api_key_here
LLM_PROVIDER=openai  # Options: openai, ollama
LLM_MODEL=gpt-4  # For OpenAI: gpt-4, gpt-3.5-turbo. For Ollama: llama3, mistral, etc.

# Option 2: Ollama (local)
# OLLAMA_BASE_URL=http://localhost:11434
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3

# Embedding Configuration
# Option 1: OpenAI Embeddings
EMBEDDING_PROVIDER=openai  # Options: openai, sentence-transformers
EMBEDDING_MODEL=text-embedding-3-small  # For OpenAI: text-embedding-3-small, text-embedding-3-large

# Option 2: Sentence Transformers (open-source)
# EMBEDDING_PROVIDER=sentence-transformers
# EMBEDDING_MODEL=all-MiniLM-L6-v2  # or all-mpnet-base-v2, sentence-transformers/all-MiniLM-L6-v2

# Vector Database Configuration
# Option 1: Pinecone
VECTOR_DB=pinecone  # Options: pinecone, chroma
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-east-1-aws  # Your Pinecone environment
PINECONE_INDEX_NAME=qa-rag-index

# Option 2: Chroma (local/open-source)
# VECTOR_DB=chroma
# CHROMA_PERSIST_DIRECTORY=./chroma_db

# Application Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RETRIEVAL=5
RETRIEVAL_SCORE_THRESHOLD=0.7

# Hybrid Retrieval Configuration
USE_HYBRID_RETRIEVAL=true  # Enable hybrid retrieval (combines semantic + keyword search)
SEMANTIC_WEIGHT=0.5  # Weight for semantic/vector search (0.0-1.0)
KEYWORD_WEIGHT=0.5  # Weight for keyword/BM25 search (0.0-1.0)

# Feedback System Configuration
FEEDBACK_STORAGE_PATH=./feedback_data.json  # Path to store feedback data
FEEDBACK_LEARNING_RATE=0.1  # Learning rate for weight updates (0.0-1.0)
FEEDBACK_MIN_SAMPLES=5  # Minimum number of rated queries before adjusting weights
AUTO_UPDATE_WEIGHTS=false  # Automatically update weights based on feedback

# Streamlit Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0

